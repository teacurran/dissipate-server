name: Deploy to Production Environment

on:
  # Only deploy after CI workflow completes successfully on main branch
  workflow_run:
    workflows: ["Continuous Integration"]
    types: [completed]
    branches:
      - main
  # Allow manual deploys
  workflow_dispatch:

env:
  REGISTRY: docker.io
  IMAGE_NAME: dissipate-server
  USE_WIREGUARD: ${{ secrets.USE_WIREGUARD || 'false' }}
  DEPLOYMENT_NAMESPACE: dissipate-production

jobs:
  # Only build if manually triggered (CI already built the image for workflow_run)
  build:
    name: Build Docker Image (manual only)
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ secrets.DOCKER_USERNAME }}/${{ env.IMAGE_NAME }}
          tags: |
            type=sha,format=long
            type=raw,value=latest

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./api/src/main/docker/Dockerfile.native
          platforms: linux/amd64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    name: Deploy to Production (k3s)
    runs-on: ubuntu-latest
    needs: [build]
    # Run if: (workflow_run from PUSH event AND CI passed AND build skipped) OR (workflow_dispatch AND build succeeded)
    if: |
      always() &&
      (
        (github.event_name == 'workflow_run' && github.event.workflow_run.event == 'push' && github.event.workflow_run.conclusion == 'success' && needs.build.result == 'skipped') ||
        (github.event_name == 'workflow_dispatch' && needs.build.result == 'success')
      )
    # IMPORTANT: This 'environment' setting creates a manual approval gate
    # Configure this in GitHub: Settings > Environments > production > Required reviewers
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: maven

      - name: Setup WireGuard
        if: env.USE_WIREGUARD == 'true'
        run: |
          sudo apt-get update
          sudo apt-get install -y wireguard-tools

          WG_ADDRESS=$(echo -n "${{ secrets.WIREGUARD_ADDRESS }}" | tr -d '[:space:]')
          WG_PRIVATE_KEY=$(echo -n "${{ secrets.WIREGUARD_PRIVATE_KEY }}" | tr -d '[:space:]')
          WG_PEER_PUBLIC_KEY=$(echo -n "${{ secrets.WIREGUARD_PEER_PUBLIC_KEY }}" | tr -d '[:space:]')
          WG_ENDPOINT=$(echo -n "${{ secrets.WIREGUARD_ENDPOINT }}" | tr -d '[:space:]')
          WG_ALLOWED_IPS=$(echo -n "${{ secrets.WIREGUARD_ALLOWED_IPS }}" | tr -d '[:space:]')

          if [[ ! "$WG_ENDPOINT" =~ ^[^:]+:[0-9]+$ ]]; then
            echo "ERROR: WIREGUARD_ENDPOINT format is invalid!"
            exit 1
          fi

          sudo mkdir -p /etc/wireguard
          sudo tee /etc/wireguard/wg0.conf > /dev/null <<EOF
          [Interface]
          Address = ${WG_ADDRESS}
          PrivateKey = ${WG_PRIVATE_KEY}

          [Peer]
          PublicKey = ${WG_PEER_PUBLIC_KEY}
          Endpoint = ${WG_ENDPOINT}
          AllowedIPs = ${WG_ALLOWED_IPS}
          PersistentKeepalive = 25
          EOF

          sudo chmod 600 /etc/wireguard/wg0.conf
          sudo wg-quick up wg0
          ping -c 3 10.50.0.20

      - name: Run MyBatis database migrations
        working-directory: api-db
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
        run: |
          echo "Running MyBatis migrations for production environment..."
          cat > src/main/resources/db/environments/production.properties <<PROPS
          time_zone=GMT+0:00
          driver=org.postgresql.Driver
          url=jdbc:postgresql://${DB_HOST}:${DB_PORT}/${DB_NAME}
          username=${DB_USER}
          password=${DB_PASSWORD}
          send_full_script=true
          delimiter=;
          full_line_delimiter=false
          auto_commit=false
          ignore_warnings=true
          changelog=CHANGELOG
          PROPS
          mvn -B migrations:up -Dmigration.env=production

      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.K3S_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

          cat >> ~/.ssh/config <<EOF
          Host *
            ServerAliveInterval 30
            ServerAliveCountMax 10
            TCPKeepAlive yes
            ConnectionAttempts 3
          EOF

          if [ "${{ env.USE_WIREGUARD }}" == "true" ]; then
            echo "Host 10.50.0.20" >> ~/.ssh/config
            echo "  StrictHostKeyChecking no" >> ~/.ssh/config
            echo "  UserKnownHostsFile /dev/null" >> ~/.ssh/config
          else
            echo "${{ secrets.K3S_HOST }} ssh-rsa ${{ secrets.K3S_HOST_KEY }}" >> ~/.ssh/known_hosts
          fi

      - name: Deploy with Ansible (Production Environment)
        env:
          REGISTRY_USER: ${{ secrets.DOCKER_USERNAME }}
          REGISTRY_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
          IMAGE_TAG: sha-${{ github.event.workflow_run.head_sha || github.sha }}
          ENVIRONMENT: production
          K3S_HOST: ${{ env.USE_WIREGUARD == 'true' && '10.50.0.20' || secrets.K3S_HOST }}
          K3S_USER: ${{ secrets.K3S_USER }}
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          KEYCLOAK_URL: https://auth.villagecompute.com
          KEYCLOAK_REALM: dissipate
          OIDC_CLIENT_ID: dissipate-app
          S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
          S3_ACCESS_KEY: ${{ secrets.S3_ACCESS_KEY }}
          S3_SECRET_KEY: ${{ secrets.S3_SECRET_KEY }}
          S3_UPLOADS_BUCKET: dissipate-production-uploads-raw
          S3_MEDIA_BUCKET: dissipate-production-media-derived
          S3_REGION: us-east-1
          S3_CDN_URL: ${{ secrets.S3_CDN_URL }}
          INGRESS_HOST: api.dissipate.app
          DEPLOYMENT_NAMESPACE: ${{ env.DEPLOYMENT_NAMESPACE }}
        run: |
          python -m pip install --upgrade pip
          pip install ansible docker

          cat > inventory.yml <<EOF
          all:
            hosts:
              k3s_cluster:
                ansible_host: ${K3S_HOST}
                ansible_user: ${K3S_USER}
                ansible_ssh_private_key_file: ~/.ssh/id_rsa
                ansible_python_interpreter: /usr/bin/python3
                ansible_ssh_common_args: '-o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=4'
                ansible_ssh_retries: 3
          EOF

          # Clone infra repo for the Ansible playbook
          git clone --depth 1 https://github.com/${{ github.repository_owner }}/villagecompute-infra.git /tmp/infra || true

          # Use local playbook if infra repo not available
          if [ -f /tmp/infra/ansible/deploy-dissipate.yml ]; then
            ansible-playbook -v -i inventory.yml /tmp/infra/ansible/deploy-dissipate.yml
          else
            echo "Infra repo not available, deploying via kubectl directly..."
            ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${K3S_USER}@${K3S_HOST} \
              "kubectl set image deployment/dissipate-app dissipate=${REGISTRY_USER}/dissipate-server:${IMAGE_TAG} -n ${DEPLOYMENT_NAMESPACE}"
          fi

      - name: Wait for rollout completion
        env:
          K3S_HOST: ${{ env.USE_WIREGUARD == 'true' && '10.50.0.20' || secrets.K3S_HOST }}
          K3S_USER: ${{ secrets.K3S_USER }}
        run: |
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR ${K3S_USER}@${K3S_HOST} \
            "kubectl rollout status deployment/dissipate-app -n ${DEPLOYMENT_NAMESPACE} --timeout=5m"

      - name: Run smoke tests
        env:
          K3S_HOST: ${{ env.USE_WIREGUARD == 'true' && '10.50.0.20' || secrets.K3S_HOST }}
          K3S_USER: ${{ secrets.K3S_USER }}
        run: |
          sleep 5

          echo "Running health check..."
          HEALTH_OUTPUT=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR -o ConnectTimeout=30 -o ServerAliveInterval=15 ${K3S_USER}@${K3S_HOST} \
            "kubectl run smoke-test-health --rm -i --restart=Never --image=curlimages/curl:latest -n ${DEPLOYMENT_NAMESPACE} -- \
            curl -s -o /dev/null -w '%{http_code}' http://dissipate-service.${DEPLOYMENT_NAMESPACE}.svc.cluster.local/q/health/live" 2>&1)

          HEALTH_STATUS=$(echo "${HEALTH_OUTPUT}" | grep -oE '[0-9]{3}' | head -1)

          echo "Health check output: ${HEALTH_OUTPUT}"
          echo "Health check status: ${HEALTH_STATUS}"
          if [ "${HEALTH_STATUS}" != "200" ]; then
            echo "Health check failed with status ${HEALTH_STATUS}"
            exit 1
          fi

          echo "All smoke tests passed!"

      - name: Disconnect WireGuard
        if: always() && env.USE_WIREGUARD == 'true'
        run: |
          sudo wg-quick down wg0 || true

      - name: Notify deployment success
        if: success()
        uses: actions/github-script@v7
        with:
          script: |
            const sha = '${{ github.sha }}';
            const shortSha = sha.substring(0, 7);

            if (context.payload.pull_request) {
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: `Deployed to production (${shortSha})\n\nView at: https://api.dissipate.app/q/health`
              });
            }

      - name: Rollback instructions
        if: failure()
        run: |
          echo "::warning::Deployment failed! To rollback, run:"
          echo "kubectl rollout undo deployment/dissipate-app -n ${DEPLOYMENT_NAMESPACE}"
          echo ""
          echo "Or manually deploy a previous version:"
          echo "kubectl set image deployment/dissipate-app dissipate=\$DOCKER_USERNAME/dissipate-server:<previous-tag> -n ${DEPLOYMENT_NAMESPACE}"
